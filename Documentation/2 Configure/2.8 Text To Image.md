# Text To Image services
- `text2img`

# Configuration example
```json
{
    "service": "text2img",
    "type": "hf",
    "model": "black-forest-labs/FLUX.1-schnell",
    "device": "cpu",
    "steps": 8,
    "guidance": 3,
    "width": 1024,
    "height": 1024,
    "threads": -1,
    "price": 0
}
```

## Parameters
Some of the parameters are the same as a general service.

## New parameters
### type
The system to use.

Set to **hf** to use HuggingFace's Diffusers.

Set to **sdcpp-flux** to use StableDiffusion.CPP for Flux models.

Set to **sdcpp-sd** to use StableDiffusion.CPP for StableDiffusion models.

#### Parameter type
string (text)

### model
This parameter may change it's type depending on what system you want to use.

#### hf
This parameter is a **string (text)** where you write the model repository in HuggingFace.

Example:
```json
"model": "black-forest-labs/FLUX.1-schnell"
```

#### sdcpp-flux / sdcpp-cpp
This parameter is a **list** where you write the model path and some other things.

There are different ways to set this parameter.

##### Local
If you have a model downloaded in your machine, set this parameter to this:
```json
"model": [
    "MODEL PATH",
    "VAE / CLIP_G MODEL PATH",
    "CLIP_L MODEL PATH",
    "T5XXL MODEL PATH"
]
```

###### MODEL PATH
This is the path of the **.safetensors** or **.gguf** model file.

###### VAE / CLIP_G MODEL PATH
This is the path of the **.safetensors** or **.gguf** VAE or CLIP_G model file.

If you're using `sdcpp-sd` it's the **CLIP_G** model path.

Otherwise, if you're using `sdcpp-flux` it's the **VAE** model path.

###### CLIP_L MODEL PATH
This is the path of the **.safetensors** or **.gguf** CLIP_L model file.

###### T5XXL MODEL PATH
This is the path of the **.safetensors** or **.gguf** T5XXL model file.

##### Pre-defined
If you want to use a pre-defined model, set this parameter to this:
```json
"model": [
    "MODEL NAME",
    "MODEL QUANTIZATION",
    "VAE / CLIP_G QUANTIZATION",
    "CLIP_L QUANTIZATION",
    "T5XXL QUANTIZATION"
]
```

###### MODEL NAME
The name of the model you want to use.

You can see the available names and quantizations at the `LibI4/Python_AI/Inference/PredefinedModels/text2img_sdcpp.yaml` file.

###### MODEL QUANTIZATION
The quantization you want to use for the model.

###### VAE / CLIP_G QUANTIZATION
The quantization you want to use for the VAE / CLIP_G model.

###### CLIP_L QUANTIZATION
The quantization you want to use for the CLIP_L model.

###### T5XXL QUANTIZATION
The quantization you want to use for the T5XXL model.

#### Parameter type
string (text) or list

### steps
The default amount of steps you want the model to take.

More steps means better results, but longer inference time.

#### Parameter type
integer (integer number)

### guidance
The default guidance scale of the model.

#### Parameter type
float (floating number)

### width
The default width of the image.

#### Parameter type
interger (integer number)

### height
The default height of the image.

#### Parameter type
integer (integer number)

### threads
The amount of threads you want to use.

#### Parameter type
integer (integer number)